{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a085a53-7949-43fc-a688-45af1dcced09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0WPylkxI7S73"
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18ff3f42-baff-40da-92b6-dcc239d9d8ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAnIgoXgv3FI",
    "outputId": "d2fa72fc-ebd9-4e8d-cacb-02687c1bc476"
   },
   "outputs": [],
   "source": [
    "# Update packages and install required java version\n",
    "!apt-get update\n",
    "!apt-get install openjdk-21-jdk-headless -qq > /dev/null\n",
    "\n",
    "# download and unzip spark\n",
    "!wget -nc -q https://downloads.apache.org/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz\n",
    "!tar xf spark-4.0.0-bin-hadoop3.tgz\n",
    "\n",
    "# get data for labs\n",
    "!wget -nc -O around_the_world_in_80_days.txt https://www.gutenberg.org/ebooks/103.txt.utf-8\n",
    "\n",
    "# install findspark\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c23d1861-cde7-428a-93b5-48366ca584a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "amepofAo0Z88"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "# set env vars for java and spark\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.0-bin-hadoop3\"\n",
    "\n",
    "# start findspark so notebook can interact with spark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f2f680c-3f09-4d93-b60d-f2cc0c98f135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Zmv2ros75Gnu"
   },
   "outputs": [],
   "source": [
    "# what does findspark do? use the ?? magic command to find out\n",
    "# Note 1: in colab, this may open in a side panel\n",
    "# Note 2: this magic command is often helpful when encountering an object in a\n",
    "# notebook that is unfamiliar. More information will be displayed if it exists\n",
    "?? findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb1e96a7-8c2a-40b3-8e4c-6e57fb002ce2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NyrzgODB7h-I"
   },
   "source": [
    "# 1. Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d3a4be9-859f-4b7e-845e-c4994290a106",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ubaJBAcmHN7w"
   },
   "source": [
    "Instructions:  \n",
    "For each cell marked \"double-click and add explanation here\" please answer the question in your own words.  \n",
    "In the section where you complete the code to perform basic nlp text cleaning and exploration tasks, the goal is to chain all of the transformations together in a single function. For learning and exploration purposes, it is acceptable to have each step seperate, but the last cell in this section should be one function with all transformations chained together.  \n",
    "For steps c and f, it is acceptable to use your favorite chatbot to generate a list of common stop words (c) and punctuation (e) for use in the code. As these are common steps in nlp/text processing tasks, there are pleanty of libraries to help with this such as nltk, but there is no need to import extra dependencies for this lab unless you are already familiar with working with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13c16fbc-3c44-45ed-9684-bc434e350ed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "sT9v8V8z3xRh"
   },
   "outputs": [],
   "source": [
    "# start a spark session and create spark context for making rdd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"word_count\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd1c9b1b-bb8e-42f1-ba01-0c40dbfae29e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WQuzr4jFgwA8"
   },
   "outputs": [],
   "source": [
    "# Defind the rdd\n",
    "rdd = sc.textFile('/content/around_the_world_in_80_days.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb2c581f-dd55-4157-85ec-1684daf650d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eDOA5KkhhEpe"
   },
   "outputs": [],
   "source": [
    "# view the first x lines of the rdd\n",
    "rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b5af559-2219-41f9-af60-f3bcad3c6743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-Ygmzp9YhIuc"
   },
   "outputs": [],
   "source": [
    "# example lambda function\n",
    "words = rdd.flatMap(lambda lines: lines.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fed225b9-5f20-4642-814d-ea92fc423010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cx0OTFbfhTmg"
   },
   "outputs": [],
   "source": [
    "# Note and explain the output of the below command\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7da16199-88e8-45bf-99dd-f37a05aa1f1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-ebu8bJo8yTa"
   },
   "source": [
    "# Explaining the command\n",
    "\n",
    "Writing a variable alone in a cell does the same as a print.\n",
    "\n",
    "Here it displays the object type of the variable \"words\" wich is a RDD object and also where it comes from \"PythonRDD.scala:56\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff3f6728-ac7b-4b05-9b79-caa2d076b92a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xSFM2oMV8a4l"
   },
   "source": [
    "<ADD EXPLANATION HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e943de4-6d69-417e-b4ab-90f8831aa257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mZ0xArEv8u_0"
   },
   "outputs": [],
   "source": [
    "# Note and explain the output of the following command, focusing on the difference with the\n",
    "# above command\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e17abb5b-ffe6-49d1-a6be-af981f3d5e2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b8xJlKEB9aDY"
   },
   "source": [
    "# Explaining the command\n",
    "\n",
    "\n",
    "The collect() function returns a list containing all the elements in the RDD words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f501ef5-0a18-459a-a380-c1babc825718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eD96cn2NhUaZ"
   },
   "outputs": [],
   "source": [
    "# nicer print\n",
    "for w in words.collect():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdda8bc2-5370-4cf0-ad8c-ad3938bd3697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "2tQ4EUF7hyDx",
    "outputId": "1c189838-480d-4217-9410-bdf5de04fb0e"
   },
   "outputs": [],
   "source": [
    "# Print first x words\n",
    "words.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22020913-1454-47b4-8696-ec5835e3c6a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "O6M0MIGmEVrq"
   },
   "outputs": [],
   "source": [
    "# Use cell magic command to help understand what the rdd.flatMap function is doing in the next cell.\n",
    "# Insert a text/markdown cell and explain in your own words.\n",
    "\n",
    "?? rdd.flatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13fe43d2-932f-493d-b2b7-825a2bc067be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Ae6LIZzHdzjj"
   },
   "source": [
    "# rdd.flatMap\n",
    "\n",
    "rdd.flatMap is a method that takes in argument a function and applies it to the Rdd passed in parameter while assigning it to a new flattened RDD. In the cell bellow it splits text lines into individual words, creates (word, 1) tuples for each word, and prints all the tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ee50305-bf98-4083-bb8f-0475a5f2bb38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "BdkOE8Pzh4sV",
    "outputId": "a1c81480-2b9f-4e3f-ae2c-e348ec469b11"
   },
   "outputs": [],
   "source": [
    "# Initialize a word counter by creating a tuple with word and cound of 1\n",
    "words = rdd.flatMap(lambda lines: lines.split(' ')) \\\n",
    "                    .map(lambda word: (word, 1))\n",
    "\n",
    "for w in words.collect():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c4ba9dc-0126-47d6-8dec-f34598678d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "hFu72I93_8CS",
    "outputId": "6c3f7772-d3c9-4604-93f3-d3f129198673"
   },
   "outputs": [],
   "source": [
    "# a. count the occurence of each word\n",
    "\n",
    "word_count= {}\n",
    "\n",
    "for w in words.collect():\n",
    "  if w[0] in word_count:\n",
    "    word_count[w[0]] += 1\n",
    "  else:\n",
    "    word_count[w[0]] = 1\n",
    "\n",
    "for w in word_count:\n",
    "  print(w, word_count[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b0b555f-2b08-4c4e-bebc-7d59c42ced8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "dYAIt8A8AGGn",
    "outputId": "f0c787ca-c4dc-4085-86e5-9d38b35ace34"
   },
   "outputs": [],
   "source": [
    "# b. a common first step in text analysis, change all capital letters to lower case\n",
    "words_lower = {}\n",
    "for word in word_count.keys():\n",
    "  words_lower[word.lower()] = word_count[word]\n",
    "\n",
    "for w in words_lower:\n",
    "  print(w, words_lower[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "932d5819-0786-4f6e-9ab4-a4770bb3f5a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "CNr23N3MAVla",
    "outputId": "d4e20fe4-e549-4948-8016-fb5e75f4c040"
   },
   "outputs": [],
   "source": [
    "# c. eliminate the stop words.\n",
    "\n",
    "words_lower_stop_words = {}\n",
    "\n",
    "stop_words = [\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\",\n",
    "    \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\",\n",
    "    \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\",\n",
    "    \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\",\n",
    "    \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\",\n",
    "    \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "    \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\",\n",
    "    \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\",\n",
    "    \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\",\n",
    "    \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\",\n",
    "    \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\",\n",
    "    \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\",\n",
    "    \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\",\n",
    "    \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\",\n",
    "    \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\",\n",
    "    \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\",\n",
    "    \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\",\n",
    "    \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\",\n",
    "    \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"\n",
    "]\n",
    "\n",
    "\n",
    "for w in words_lower:\n",
    "  if  w not in stop_words:\n",
    "    words_lower_stop_words[w] = words_lower[w]\n",
    "\n",
    "for w in words_lower_stop_words:\n",
    "  print(w, words_lower_stop_words[w])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54238858-c1a8-4cb3-8c7c-f46dc8f9c392",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "HjOm9cn7B5lI",
    "outputId": "e5c37df5-658e-49d0-e89f-0d885a9602f7"
   },
   "outputs": [],
   "source": [
    "# d. sort in alphabetical order\n",
    "\n",
    "words_lower_stop_words_sorted = {}\n",
    "\n",
    "for w in sorted(words_lower_stop_words):\n",
    "  words_lower_stop_words_sorted[w] = words_lower_stop_words[w]\n",
    "\n",
    "for w in words_lower_stop_words_sorted:\n",
    "  print(w, words_lower_stop_words_sorted[w])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "336d209f-2e83-4e8e-a942-2f674ab37094",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "WXrqvUwuCD5E",
    "outputId": "88b6652e-8a75-4296-8d84-009416139fbf"
   },
   "outputs": [],
   "source": [
    "# e. sort descending by word frequency\n",
    "\n",
    "words_lower_stop_words_sorted_freq = {}\n",
    "\n",
    "for w in sorted(words_lower_stop_words_sorted, key=words_lower_stop_words_sorted.get, reverse=True):\n",
    "  words_lower_stop_words_sorted_freq[w] = words_lower_stop_words_sorted[w]\n",
    "\n",
    "\n",
    "for i, w in enumerate(words_lower_stop_words_sorted_freq ):\n",
    "  print(w, words_lower_stop_words_sorted_freq[w])\n",
    "  if i > 10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55576f8d-8f30-437b-940f-afc30bda4885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "85JlTrPckK1C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1106db9-0cad-437e-822a-5e253ddab2d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "AJr1n25lCN2B",
    "outputId": "d91d5eee-f27f-490f-b427-8115856ec21c"
   },
   "outputs": [],
   "source": [
    "# f. remove punctuations and blank spaces\n",
    "\n",
    "words_lower_stop_words_sorted_freq_punc: dict[str, int] = {}\n",
    "\n",
    "punctuations = [\n",
    "    \"!\", '\"', \"#\", \"$\", \"£\", \"€\", '•', \"%\", \"&\", \"'\", \"(\", \")\", \"*\", \"+\", \",\", \"-\", \".\", \"/\",\n",
    "    \":\", \";\", \"<\", \"=\", \">\", \"?\", \"@\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", \"`\", \"{\", \"|\",\n",
    "    \"}\", \"~\", \" \", \"“\", \"—\", \"”\", \"‘\", \"’\"\n",
    "]\n",
    "\n",
    "for w, freq in words_lower_stop_words_sorted.items():\n",
    "    cleaned = w\n",
    "    for p in punctuations:\n",
    "        cleaned = cleaned.replace(p, \"\")\n",
    "    cleaned = cleaned.strip()\n",
    "    if cleaned:\n",
    "        words_lower_stop_words_sorted_freq_punc[cleaned] = freq\n",
    "\n",
    "for i, (w, freq) in enumerate(words_lower_stop_words_sorted_freq_punc.items()):\n",
    "    print(w, freq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55762801-5ed6-4687-95f4-224113e3486e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "81MYw5zXCv8X"
   },
   "source": [
    "# 2. What does the following cell block do?\n",
    "Comment the code below line by line after the provided hash-tag. You should be able to explain each line while respecting the pep8 style guide of 79 characters or less per line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffdac258-86c8-410b-ad5a-5b0c7f06aa7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "FrrNF7seCaZ2",
    "outputId": "5731dd00-8b71-466f-b665-4b83c5df0dcb"
   },
   "outputs": [],
   "source": [
    " # Create an RDD of tuples (name, age)\n",
    "dataRDD = sc.parallelize([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    "(\"TD\", 35), (\"Brooke\", 25)])\n",
    "\n",
    "# Try to undestand what this code does (line by line)\n",
    "agesRDD = (dataRDD\n",
    "  #Transform each record into (name,(age,1)), preparing for the aggregation\n",
    "  .map(lambda x: (x[0], (x[1], 1)))\n",
    "  #Groups by name and sums ages (x[0] + y[0]) and counts (x[1]+y[1])\n",
    "  .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "  #Now we compute the average age per name by dividing total age by total count\n",
    "  .map(lambda x: (x[0], x[1][0]/x[1][1])))\n",
    "\n",
    "print(agesRDD.collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4f654ba-c4f0-4346-a27e-b97eccb1e0b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Rzas64DSRt_a"
   },
   "source": [
    "# Where to go from here\n",
    "\n",
    "Further exploration for students who complete the lab before the end of the session or want to go further.\n",
    "\n",
    "- perform eda on the original french version of the [book](https://www.gutenberg.org/ebooks/46541.txt.utf-8) and compare the two\n",
    "- recomplete the exercises using a the docker install\n",
    "- install java and spark directly onto host machine and either rexplore this notebook or perform eda on other data sets\n",
    "- write a simple python timer function for seeing how quickly your rdd runs as written. change the order of the steps in order to make the rdd run as optimally as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dd34c1b-0cb4-43ae-b186-a854d96680ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "background_save": true
    },
    "id": "XH329uSEU0s_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "LAB1 Wordcount",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
