{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e3674a-0e18-49ea-bf42-801c93d106a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exploratory Data Analysis with Pyspark and Spark SQL \n",
    "\n",
    "By Tom Urban and Ethan Smadja Gr3\n",
    "\n",
    "The following notebook utilizes New York City taxi data from [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Load and explore nyc taxi data from january 0f 2019. The exercises can be executed using pyspark or spark sql ( a subset of the questions will be re-answered using the language not chosen for the  main work).\n",
    "- Load the zone lookup table to answer the questions about the nyc boroughs.  \n",
    "- Load nyc taxi data from January of 2025 and compare data.  \n",
    "- With any remaining time, work on the where to go from here section.  \n",
    "- Lab due date is TBD ( due dates will be updated in the readme for the class repo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f445f856-1ce8-4dc7-88e2-90d7aed027ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the name of the new catalog\n",
    "catalog = 'taxi_eda_db'\n",
    "\n",
    "# define variables for the trips data\n",
    "schema = 'yellow_taxi_trips'\n",
    "volume = 'data'\n",
    "file_name = 'yellow_tripdata_2019-01.parquet'\n",
    "table_name = 'tbl_yellow_taxi_trips'\n",
    "path_volume = '/Volumes/' + catalog + \"/\" + schema + '/' + volume\n",
    "path_table =  catalog + \".\" + schema\n",
    "download_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-01.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "545e8186-b880-4cb8-a5f6-d73e4b407a3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the catalog/schema/volume\n",
    "spark.sql('create catalog if not exists ' + catalog)\n",
    "spark.sql('create schema if not exists ' + catalog + '.' + schema)\n",
    "spark.sql('create volume if not exists ' + catalog + '.' + schema + '.' + volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef8576a8-5cbe-43f6-afc0-a0c844b66755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "dbutils.fs.cp(f\"{download_url}\", f\"{path_volume}\" + \"/\" + f\"{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be82981b-8af8-4821-a20f-e1c5ffbde15b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the dataframe\n",
    "df_trips = spark.read.parquet(f\"{path_volume}/{file_name}\",\n",
    "  header=True,\n",
    "  inferSchema=True,\n",
    "  sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bffe652-71fd-404e-913d-7f368427d7c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show the dataframe\n",
    "df_trips.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95c3add9-ff1a-4570-aa20-c65a4dc0514f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Lab\n",
    "\n",
    "### Part 1\n",
    "This section can be completed either using pyspark commands or sql commands ( There will be a section after in which a self-chosen subset of the questions are re-answered using the language not used for the main section. i.e. if pyspark is chosen for the main lab, sql should be used to repeat some of the questions. )\n",
    "\n",
    "- Add a column that creates a unique key to identify each record in order to answer questions about individual trips\n",
    "- Which trip has the highest passanger count\n",
    "- What is the Average passanger count\n",
    "- Shortest/longest trip by distance? by time?.\n",
    "- busiest day/slowest single day\n",
    "- busiest/slowest time of day ( you may want to bucket these by hour or create timess such as morning, afternoon, evening, late night )\n",
    "- On average which day of the week is slowest/busiest\n",
    "- Does trip distance or num passangers affect tip amount\n",
    "- What was the highest \"extra\" charge and which trip\n",
    "- Are there any datapoints that seem to be strange/outliers (make sure to explain your reasoning in a markdown cell)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e911a5d1-2be3-442b-a366-cf36c550175d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 1 : Add a column that creates a unique key to identify each record in order to answer questions about individual trips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30702860-d1de-41e3-9046-04b52d431560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's import a function that generates a column with monotonically increasing 64-bit integers\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# here we create the column and apply the function\n",
    "df_trips = df_trips.withColumn(\"trip_id\", monotonically_increasing_id())\n",
    "\n",
    "display(df_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b7ed670-e2e2-488d-99f2-9e84ab9b348f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Which trip has the highest passanger count ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "090b9266-3c88-403a-ade4-ee1958f64a62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# the desc function returns a sort expression for the target column in descending order\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# let's use this function help to orderBy and display the first row wich correspond to the highest passanger count \n",
    "trip_max_passenger = df_trips.orderBy(desc(\"passenger_count\")).limit(1).select(\"passenger_count\", \"trip_id\")\n",
    "display(trip_max_passenger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff202793-e832-41f4-9b24-dbcbd9dda7dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- What is the Average passanger count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b80ebf0-7f48-470f-95f7-5e75a3f0a235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the average passenger count\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Compute the average and add a comment to the result column\n",
    "avg_passenger_count = df_trips.agg(avg(\"passenger_count\").alias(\"average_passenger_count\"))\n",
    "\n",
    "display(avg_passenger_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74cd4be5-a632-4af4-8216-c8b318facb5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Shortest/longest trip by distance? by time?.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89fa7d0b-2b27-45c6-9b79-a2de75a7218f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp, min as spark_min, max as spark_max\n",
    "\n",
    "# Calculate trip duration in seconds\n",
    "df_trips = df_trips.withColumn(\n",
    "    \"trip_duration_sec\",\n",
    "    unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")\n",
    ")\n",
    "\n",
    "# Shortest and longest trip by distance\n",
    "shortest_trip_distance = df_trips.orderBy(\n",
    "    col(\"trip_distance\").asc()\n",
    ").limit(1).select(\"trip_distance\", \"trip_id\")\n",
    "\n",
    "longest_trip_distance = df_trips.orderBy(\n",
    "    col(\"trip_distance\").desc()\n",
    ").limit(1).select(\"trip_distance\", \"trip_id\")\n",
    "\n",
    "# Shortest and longest trip by duration\n",
    "shortest_trip_time = df_trips.orderBy(\n",
    "    col(\"trip_duration_sec\").asc()\n",
    ").limit(1).select(\"trip_duration_sec\", \"trip_id\")\n",
    "\n",
    "longest_trip_time = df_trips.orderBy(\n",
    "    col(\"trip_duration_sec\").desc()\n",
    ").limit(1).select(\"trip_duration_sec\", \"trip_id\")\n",
    "\n",
    "#  display the results with .show()\n",
    "print(\"the shortest trip by distance is :\")\n",
    "shortest_trip_distance.show()\n",
    "\n",
    "print(\"the longest trip by distance is :\")\n",
    "longest_trip_distance.show()\n",
    "\n",
    "print(\"the shortest trip by time is :\")\n",
    "shortest_trip_time.show()\n",
    "\n",
    "print(\"the longest trip by time is:\")\n",
    "longest_trip_time.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03779595-f5de-4382-8129-6cfe2b76db55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "we can see here that there are outliers values in the dataset since there is negative trip duration value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28680dfb-356b-4544-988c-ed1b3163635b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Busiest / Slowest single day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a005634-5eb9-4dc5-925d-9392e1d2dfd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col, count\n",
    "\n",
    "# Extract pickup date\n",
    "df_trips = df_trips.withColumn(\"pickup_date\", to_date(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Count trips per day\n",
    "trips_per_day = df_trips.groupBy(\"pickup_date\").agg(count(\"*\").alias(\"num_trips\"))\n",
    "\n",
    "# Busiest and slowest days\n",
    "busiest_day = trips_per_day.orderBy(col(\"num_trips\").desc()).limit(1)\n",
    "slowest_day = trips_per_day.orderBy(col(\"num_trips\").asc()).limit(1)\n",
    "\n",
    "busiest_day.show()\n",
    "slowest_day.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43925b7a-5938-420f-864d-622de8a9f92b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Busiest / Slowest time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac6594ed-4f2e-43d6-9f9a-14dec3d146ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour\n",
    "\n",
    "# Extract the hour from the pickup datetime\n",
    "df_trips = df_trips.withColumn(\"pickup_hour\", hour(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Count how many trips started in each hour\n",
    "trips_per_hour = df_trips.groupBy(\"pickup_hour\").agg(count(\"*\").alias(\"num_trips\"))\n",
    "\n",
    "# Find the busiest and slowest hours\n",
    "busiest_hour = trips_per_hour.orderBy(col(\"num_trips\").desc()).limit(1)\n",
    "slowest_hour = trips_per_hour.orderBy(col(\"num_trips\").asc()).limit(1)\n",
    "\n",
    "# Show the results\n",
    "busiest_hour.show()\n",
    "slowest_hour.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900ac220-e09c-4c28-af42-5a8c2ea8512b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Find the busiest and slowest day of the week (on average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65242a6c-0e63-4e3f-b7bf-a409228ec326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofweek\n",
    "\n",
    "# Extract the day of the week from the pickup date\n",
    "df_trips = df_trips.withColumn(\"day_of_week\", dayofweek(col(\"pickup_date\")))\n",
    "\n",
    "# Count total trips for each day of the week\n",
    "avg_trips_by_day = df_trips.groupBy(\"day_of_week\").agg(count(\"*\").alias(\"num_trips\"))\n",
    "\n",
    "# Show which day of the week is the busiest and slowest\n",
    "avg_trips_by_day.orderBy(col(\"num_trips\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "923d09a7-3a01-4876-8ecd-2a88811cf782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Check if distance or passengers affect the tip amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec3f3f04-09db-4aae-8fe5-2ee30b2861d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate correlation between trip distance and tip amount\n",
    "print(\"Correlation (distance vs tip):\", df_trips.stat.corr(\"trip_distance\", \"tip_amount\"))\n",
    "\n",
    "# Calculate correlation between passenger count and tip amount\n",
    "print(\"Correlation (passengers vs tip):\", df_trips.stat.corr(\"passenger_count\", \"tip_amount\"))\n",
    "\n",
    "# Show average tip amount by passenger count\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_trips.groupBy(\"passenger_count\").agg(avg(\"tip_amount\").alias(\"avg_tip\")).orderBy(\"passenger_count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43a7091-5cd6-4617-9d2e-62e8002287dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- What was the highest \"extra\" charge and which trip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10adb5a3-81d7-4c21-bf62-7a65dbeaf5f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "# Find the maximum extra charge\n",
    "max_extra = df_trips.agg(max(\"extra\").alias(\"max_extra\")).collect()[0][\"max_extra\"]\n",
    "\n",
    "# Show the trip(s) that had this highest extra charge\n",
    "df_trips.filter(col(\"extra\") == max_extra).select(\"trip_id\", \"extra\", \"tpep_pickup_datetime\", \"trip_distance\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5633484-9408-46b6-8309-897b119e4c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Are there any datapoints that seem to be strange/outliers (make sure to explain your reasoning in a markdown cell)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bba1d146-73dd-446b-81ca-42f98b215911",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_trips.filter(\n",
    "    (col(\"trip_distance\") <= 0) |      # distance cannot be 0 or negative\n",
    "    (col(\"fare_amount\") < 0) |         # fare cannot be negative\n",
    "    (col(\"passenger_count\") > 6)       # more than 6 passengers is unusual\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c46dfc65-2208-4003-96eb-2a7a685267f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Some trips show unrealistic values such as a distance of 0 or negative, negative fares, or more than six passengers.\n",
    "These data points are likely caused by data entry or recording errors and should be treated as outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa17875-d29e-4130-84c7-9d4f0d2c3724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa2f5628-1cbd-4195-98f2-c996ca243535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Part 2\n",
    "\n",
    "- Using the code for loading the first dataset as an example, load in the taxi zone lookup and answer the following questions\n",
    "- which borough had most pickups? dropoffs?\n",
    "- what are the busy/slow times by borough \n",
    "- what are the busiest days of the week by borough?\n",
    "- what is the average trip distance by borough?\n",
    "- what is the average trip fare by borough?\n",
    "- highest/lowest faire amounts for a trip, what burough is associated with the each\n",
    "- load the dataset from the most recently available january, is there a change to any of the average metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be379f02-8a07-47ca-a0c8-ca3f7d5e0595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load the taxi zone lookup dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bdaad62-6734-4b98-a255-2e0d921d0732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define variables for the taxi zone lookup file\n",
    "zone_schema = 'taxi_zone_lookup'\n",
    "zone_volume = 'data'\n",
    "zone_file_name = 'taxi+_zone_lookup.csv'\n",
    "zone_table_name = 'tbl_taxi_zone_lookup'\n",
    "zone_path_volume = '/Volumes/' + catalog + \"/\" + zone_schema + '/' + zone_volume\n",
    "zone_path_table = catalog + \".\" + zone_schema\n",
    "zone_download_url = 'https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv'\n",
    "\n",
    "# Create the schema and volume if they don't exist\n",
    "spark.sql('create schema if not exists ' + catalog + '.' + zone_schema)\n",
    "spark.sql('create volume if not exists ' + catalog + '.' + zone_schema + '.' + zone_volume)\n",
    "\n",
    "# Download the lookup CSV file into your volume\n",
    "dbutils.fs.cp(f\"{zone_download_url}\", f\"{zone_path_volume}/{zone_file_name}\")\n",
    "\n",
    "# Load the lookup table into a Spark DataFrame\n",
    "df_zones = spark.read.csv(f\"{zone_path_volume}/{zone_file_name}\", header=True, inferSchema=True)\n",
    "\n",
    "df_zones.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c5aca29-7363-401f-af59-9103a991d55e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Join trips with zone lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6ebf31-dc44-49e5-8606-f4f378f28e64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Join for pickup borough\n",
    "df_trips = df_trips.join(\n",
    "    df_zones.withColumnRenamed(\"LocationID\", \"PULocationID_lookup\"),\n",
    "    df_trips[\"PULocationID\"] == col(\"PULocationID_lookup\"),\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"Borough\", \"pickup_borough\")\n",
    "\n",
    "# Join for dropoff borough\n",
    "df_trips = df_trips.join(\n",
    "    df_zones.withColumnRenamed(\"LocationID\", \"DOLocationID_lookup\"),\n",
    "    df_trips[\"DOLocationID\"] == col(\"DOLocationID_lookup\"),\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"Borough\", \"dropoff_borough\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d36aba6-a8cd-48dd-8bff-768cbe072ff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- which borough had most pickups? dropoffs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b014d82a-e23c-4ce4-b306-e22288c4b90c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Count pickups per borough\n",
    "pickup_counts = df_trips.groupBy(\"pickup_borough\").agg(count(\"*\").alias(\"num_pickups\")).orderBy(col(\"num_pickups\").desc())\n",
    "pickup_counts.show()\n",
    "\n",
    "# Count dropoffs per borough\n",
    "dropoff_counts = df_trips.groupBy(\"dropoff_borough\").agg(count(\"*\").alias(\"num_dropoffs\")).orderBy(col(\"num_dropoffs\").desc())\n",
    "dropoff_counts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "251a4f97-37a9-45aa-9bbb-ea712d84ee8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- what are the busy/slow times by borough \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e97d2e6a-acb5-4ded-93dc-0c60759478c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Group by pickup_borough and hour\n",
    "trips_by_borough_hour = df_trips.groupBy(\"pickup_borough\", \"pickup_hour\").agg(count(\"*\").alias(\"num_trips\"))\n",
    "\n",
    "# Show the busiest hours for each borough\n",
    "trips_by_borough_hour.orderBy(col(\"pickup_borough\"), col(\"num_trips\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd295288-cb94-4b82-a60f-92ae4fd010dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- what are the busiest days of the week by borough?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bdadf50-53c3-4fc3-b833-a94e54f15ff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "trips_by_borough_day = df_trips.groupBy(\"pickup_borough\", \"day_of_week\").agg(count(\"*\").alias(\"num_trips\"))\n",
    "\n",
    "# Show results\n",
    "trips_by_borough_day.orderBy(col(\"pickup_borough\"), col(\"num_trips\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3249dd7b-c706-426e-b3ba-3753e1e1752a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- highest/lowest fare amounts for a trip, what borough is associated with the each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d16a5592-4385-474d-a8a2-30013f1b6ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql.functions import max, min\n",
    "\n",
    "# Highest fare by borough\n",
    "max_fares = df_trips.groupBy(\"pickup_borough\").agg(max(\"fare_amount\").alias(\"max_fare\"))\n",
    "max_fares.show()\n",
    "\n",
    "# Lowest fare by borough\n",
    "min_fares = df_trips.groupBy(\"pickup_borough\").agg(min(\"fare_amount\").alias(\"min_fare\"))\n",
    "min_fares.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "156cad6a-85e9-4c8d-8e25-be7f2c3d40c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- what is the average trip distance by borough?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe36872d-607d-40e6-82c0-2a5ac319e871",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Average distance per pickup borough\n",
    "avg_distance = df_trips.groupBy(\"pickup_borough\").agg(avg(\"trip_distance\").alias(\"avg_distance\"))\n",
    "avg_distance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e558d90c-c24d-4c21-91d0-c507b8bb8f75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- what is the average trip fare by borough?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc6a0af-96e4-4ce6-84c3-e1d3fb769393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Average fare per pickup borough\n",
    "avg_fare = df_trips.groupBy(\"pickup_borough\").agg(avg(\"fare_amount\").alias(\"avg_fare\"))\n",
    "avg_fare.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f25e9b7b-21bd-4fd4-b674-7569fdeb80e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- load the dataset from the most recently available january, is there a change to any of the average metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29970b5-12ef-4308-bc83-7497dd736dcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "latest_file = 'yellow_tripdata_2025-01.parquet'\n",
    "latest_download_url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/{latest_file}'\n",
    "\n",
    "# Copy and load the new data\n",
    "dbutils.fs.cp(latest_download_url, f\"{path_volume}/{latest_file}\")\n",
    "\n",
    "# Read the latest dataset\n",
    "df_trips_latest = spark.read.parquet(f\"{path_volume}/{latest_file}\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "\n",
    "# Join with the taxi zone lookup to get borough names\n",
    "# Join for pickup borough\n",
    "df_trips_latest = df_trips_latest.join(\n",
    "    df_zones.withColumnRenamed(\"LocationID\", \"PULocationID_lookup\"),\n",
    "    df_trips_latest[\"PULocationID\"] == col(\"PULocationID_lookup\"),\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"Borough\", \"pickup_borough\")\n",
    "  \n",
    "#Average trip distance per pickup borough\n",
    "avg_distance_latest = (\n",
    "    df_trips_latest.groupBy(\"pickup_borough\")\n",
    "    .agg(avg(\"trip_distance\").alias(\"avg_trip_distance\"))\n",
    "    .orderBy(col(\"avg_trip_distance\").desc())\n",
    ")\n",
    "\n",
    "print(\"Average Trip Distance by Borough (January 2025):\")\n",
    "avg_distance_latest.show()\n",
    "\n",
    "# Average fare amount per pickup borough\n",
    "avg_fare_latest = (\n",
    "    df_trips_latest.groupBy(\"pickup_borough\")\n",
    "    .agg(avg(\"fare_amount\").alias(\"avg_fare_amount\"))\n",
    "    .orderBy(col(\"avg_fare_amount\").desc())\n",
    ")\n",
    "\n",
    "print(\"Average Fare Amount by Borough (January 2025):\")\n",
    "avg_fare_latest.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64bb1754-3af5-4ff4-a8b1-51c50cca4f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- **Trip distances** increased significantly in 2025, especially in the **Bronx** and **Brooklyn**, which may suggest longer routes or data recording changes.  \n",
    "- **Fares** generally rose, especially for **Queens** and **EWR (Newark Airport)**, possibly reflecting higher fuel costs or fare adjustments.  \n",
    "- **Manhattan** still has the **shortest and cheapest trips**, consistent with its dense urban layout.  \n",
    "- **Staten Island** shows a notable **drop in fare and distance**, possibly due to fewer long-distance trips or outlier filtering differences.  \n",
    "- The **N/A and Unknown** categories likely represent incomplete location data and should be interpreted cautiously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d04e8b-17ae-46f3-80f6-875c244fd834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70500fa8-1b6f-48b8-8fec-4bb988a9f183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Part 3\n",
    "\n",
    "- choose 3 questions from above and re-answer them using the language you did not use for the main notebook . (i.e - if you completed the exercise in python, redo 3 questions in pure sql) . at least one of the questions to be redone must involve a join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d38e115b-149e-4889-a387-c5f7c159e187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temporary view for SQL queries\n",
    "df_trips_latest.createOrReplaceTempView(\"yellow_trips_latest\")\n",
    "df_zones.createOrReplaceTempView(\"taxi_zones\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1f8d6bf-3890-431d-8889-01291fcb2f08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Busy/slow times by borough (hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41df9394-6155-4991-b0e6-3bdc21402c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    pickup_borough,\n",
    "    HOUR(tpep_pickup_datetime) AS pickup_hour,\n",
    "    COUNT(*) AS trip_count\n",
    "FROM yellow_trips_latest\n",
    "WHERE pickup_borough IS NOT NULL\n",
    "GROUP BY pickup_borough, HOUR(tpep_pickup_datetime)\n",
    "ORDER BY pickup_borough, trip_count DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5449e0e6-e0b4-482e-aec1-06ac1a2a2112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Busiest days of the week by borough (with JOIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc133a5-0e4f-4514-9e8d-f43a4fa6f7a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    z.Borough AS pickup_borough,\n",
    "    date_format(t.tpep_pickup_datetime, 'E') AS day_of_week,\n",
    "    COUNT(*) AS trip_count\n",
    "FROM yellow_trips_latest AS t\n",
    "LEFT JOIN taxi_zones AS z\n",
    "    ON t.PULocationID = z.LocationID\n",
    "WHERE z.Borough IS NOT NULL\n",
    "GROUP BY z.Borough, date_format(t.tpep_pickup_datetime, 'E')\n",
    "ORDER BY z.Borough, trip_count DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4577a0-2664-4046-a7df-f66972512c6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Average trip distance by borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9d3a839-93f7-4aab-abb1-be59004afc40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    pickup_borough,\n",
    "    ROUND(AVG(trip_distance), 2) AS avg_trip_distance\n",
    "FROM yellow_trips_latest\n",
    "WHERE pickup_borough IS NOT NULL\n",
    "GROUP BY pickup_borough\n",
    "ORDER BY avg_trip_distance DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4376b74-d167-4516-a30c-0f28fbed0430",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Part 4\n",
    "\n",
    "As of spark v4 dataframes have native visualization support. Choose at least 3 questions from above and provide visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f5b59a-d1df-4073-8bfd-2de7ec4026f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGF2ZywgY29sCgojIENhbGN1bGF0ZSBhdmVyYWdlIHRyaXAgZGlzdGFuY2UgcGVyIHBpY2t1cCBib3JvdWdoCmF2Z19kaXN0YW5jZV9ieV9ib3JvdWdoID0gKAogICAgZGZfdHJpcHNfbGF0ZXN0Lmdyb3VwQnkoInBpY2t1cF9ib3JvdWdoIikKICAgIC5hZ2coYXZnKCJ0cmlwX2Rpc3RhbmNlIikuYWxpYXMoImF2Z190cmlwX2Rpc3RhbmNlIikpCiAgICAub3JkZXJCeShjb2woImF2Z190cmlwX2Rpc3RhbmNlIikuZGVzYygpKQopCgoKZGlzcGxheShhdmdfZGlzdGFuY2VfYnlfYm9yb3VnaCkgCg==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView38d75ac\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView38d75ac\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView38d75ac\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView38d75ac) SELECT `pickup_borough`,SUM(`avg_trip_distance`) `column_7c505e30229` FROM q GROUP BY `pickup_borough`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView38d75ac\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "pickup_borough",
             "id": "column_7c505e30228"
            },
            "y": [
             {
              "column": "avg_trip_distance",
              "id": "column_7c505e30229",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_7c505e30229": {
             "color": "#FFAB00",
             "name": "avg_trip_distance",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "ab7809c3-0df5-42dd-9160-e17e18f116c1",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 11.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "pickup_borough",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "pickup_borough",
           "type": "column"
          },
          {
           "alias": "column_7c505e30229",
           "args": [
            {
             "column": "avg_trip_distance",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col\n",
    "\n",
    "# Calculate average trip distance per pickup borough\n",
    "avg_distance_by_borough = (\n",
    "    df_trips_latest.groupBy(\"pickup_borough\")\n",
    "    .agg(avg(\"trip_distance\").alias(\"avg_trip_distance\"))\n",
    "    .orderBy(col(\"avg_trip_distance\").desc())\n",
    ")\n",
    "\n",
    "\n",
    "display(avg_distance_by_borough) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84c7f41-bf23-4dc5-a58c-56a637165640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBDYWxjdWxhdGUgYXZlcmFnZSBmYXJlIHBlciBwaWNrdXAgYm9yb3VnaAphdmdfZmFyZV9ieV9ib3JvdWdoID0gKAogICAgZGZfdHJpcHNfbGF0ZXN0Lmdyb3VwQnkoInBpY2t1cF9ib3JvdWdoIikKICAgIC5hZ2coYXZnKCJmYXJlX2Ftb3VudCIpLmFsaWFzKCJhdmdfZmFyZSIpKQogICAgLm9yZGVyQnkoY29sKCJhdmdfZmFyZSIpLmRlc2MoKSkKKQoKCmRpc3BsYXkoYXZnX2ZhcmVfYnlfYm9yb3VnaCkgIAo=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewa4663ce\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewa4663ce\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewa4663ce\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewa4663ce) SELECT `pickup_borough`,SUM(`avg_fare`) `column_7c505e30235` FROM q GROUP BY `pickup_borough`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewa4663ce\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "pickup_borough",
             "id": "column_7c505e30234"
            },
            "y": [
             {
              "column": "avg_fare",
              "id": "column_7c505e30235",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "pie",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_7c505e30235": {
             "name": "avg_fare",
             "type": "pie",
             "yAxis": 0
            }
           },
           "showDataLabels": true,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "bed438c4-8409-49af-9922-7ddc2bd0fa3e",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 11.75,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "pickup_borough",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "pickup_borough",
           "type": "column"
          },
          {
           "alias": "column_7c505e30235",
           "args": [
            {
             "column": "avg_fare",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate average fare per pickup borough\n",
    "avg_fare_by_borough = (\n",
    "    df_trips_latest.groupBy(\"pickup_borough\")\n",
    "    .agg(avg(\"fare_amount\").alias(\"avg_fare\"))\n",
    "    .orderBy(col(\"avg_fare\").desc())\n",
    ")\n",
    "\n",
    "\n",
    "display(avg_fare_by_borough)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "029313a1-36e5-4775-a7ad-31467a2fea7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBDYWxjdWxhdGUgYXZlcmFnZSBmYXJlIHBlciBwaWNrdXAgYm9yb3VnaAphdmdfZmFyZV9ieV9ib3JvdWdoID0gKAogICAgZGZfdHJpcHNfbGF0ZXN0Lmdyb3VwQnkoInBpY2t1cF9ib3JvdWdoIikKICAgIC5hZ2coYXZnKCJmYXJlX2Ftb3VudCIpLmFsaWFzKCJhdmdfZmFyZSIpKQogICAgLm9yZGVyQnkoY29sKCJhdmdfZmFyZSIpLmRlc2MoKSkKKQoKZGlzcGxheShhdmdfZmFyZV9ieV9ib3JvdWdoKSAK\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewb15869b\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewb15869b\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewb15869b\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewb15869b) SELECT `pickup_borough`,SUM(`avg_fare`) `column_7c505e30241` FROM q GROUP BY `pickup_borough`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewb15869b\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "pickup_borough",
             "id": "column_7c505e30240"
            },
            "y": [
             {
              "column": "avg_fare",
              "id": "column_7c505e30241",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "avg_fare": {
             "name": "avg_fare",
             "type": "column",
             "yAxis": 0
            },
            "column_7c505e30241": {
             "color": "#AB4057",
             "name": "avg_fare",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "888c0926-f6ec-49d7-8e18-5edaeeb0c556",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 11.875,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "pickup_borough",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "pickup_borough",
           "type": "column"
          },
          {
           "alias": "column_7c505e30241",
           "args": [
            {
             "column": "avg_fare",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate average fare per pickup borough\n",
    "avg_fare_by_borough = (\n",
    "    df_trips_latest.groupBy(\"pickup_borough\")\n",
    "    .agg(avg(\"fare_amount\").alias(\"avg_fare\"))\n",
    "    .orderBy(col(\"avg_fare\").desc())\n",
    ")\n",
    "\n",
    "display(avg_fare_by_borough) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22d71458-86fd-4602-aba5-cca2e9a7054f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Where to go from here\n",
    "\n",
    "- Continue building the dataset by loading in more data, start by completing the data for 2019 and calculating the busiest season (fall, winter, spring, summer)\n",
    "- Explore a dataset/datasets of your choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6630ce8f-d200-4ca6-a787-05917d31c127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "catalog = \"taxi_eda_db\"\n",
    "schema = \"yellow_taxi_trips\"\n",
    "volume = \"data\"\n",
    "path_volume = f\"/Volumes/{catalog}/{schema}/{volume}\"\n",
    "\n",
    "months = [f\"{m:02d}\" for m in range(1, 13)]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df_2019 = None\n",
    "\n",
    "for m in months:\n",
    "    file_name = f\"yellow_tripdata_2019-{m}.parquet\"\n",
    "    download_url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{file_name}\"\n",
    "    target_path = f\"{path_volume}/{file_name}\"\n",
    "\n",
    "    \n",
    "    df_2019 = df_month if df_2019 is None else df_2019.union(df_month)\n",
    "    \n",
    "print(\"dataset fully loaded\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cc06c3e-ce74-43c7-8310-58645adbbed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Add a Season Column\n",
    "\n",
    "We can define seasons by month:\n",
    "\n",
    "Winter: DecFeb (12, 1, 2)\n",
    "\n",
    "Spring: MarMay (3, 4, 5)\n",
    "\n",
    "Summer: JunAug (6, 7, 8)\n",
    "\n",
    "Fall: SepNov (9, 10, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa9d2da-76a6-4ff7-ae5e-9959295e9845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month, when, count\n",
    "\n",
    "df_2019 = df_2019.withColumn(\"month\", month(\"tpep_pickup_datetime\"))\n",
    "\n",
    "df_2019 = df_2019.withColumn(\n",
    "    \"season\",\n",
    "    when(F.col(\"month\").isin(12, 1, 2), \"Winter\")\n",
    "    .when(F.col(\"month\").isin(3, 4, 5), \"Spring\")\n",
    "    .when(F.col(\"month\").isin(6, 7, 8), \"Summer\")\n",
    "    .otherwise(\"Fall\")\n",
    ")\n",
    "\n",
    "# Find busiest season\n",
    "busiest_season = (\n",
    "    df_2019.groupBy(\"season\")\n",
    "    .agg(count(\"*\").alias(\"trip_count\"))\n",
    "    .orderBy(F.col(\"trip_count\").desc())\n",
    ")\n",
    "\n",
    "display(busiest_season)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b94c2f4c-7329-4e6a-8420-759cd4756633",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Spotify Tracks Dataset  PySpark Analysis\n",
    "\n",
    "Dataset: *Ultimate Spotify Tracks DB* (Kaggle)\n",
    "\n",
    "#### Key Transformations\n",
    "- Converted Kaggle dataset from Pandas  Spark DataFrame.\n",
    "- Added derived columns (`energy_level`, `mood`, `loudness_level`).\n",
    "- Grouped and aggregated data by genre, mood, and energy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a972b1-8c67-430a-8136-3c01d15e1e07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Tlcharge le dataset\n",
    "path = kagglehub.dataset_download(\"zaheenhamidani/ultimate-spotify-tracks-db\")\n",
    "\n",
    "# Vrifie les fichiers tlchargs\n",
    "import os\n",
    "print(os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abcf48d3-1bf6-445a-970c-a36087a2e22c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the CSV into a pandas dataframe\n",
    "file_path = os.path.join(path, \"SpotifyFeatures.csv\")\n",
    "df_spotify_pd = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "print(df_spotify_pd.shape)\n",
    "df_spotify_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abfccde4-6149-46b7-abea-d3ddfd2a0030",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, when, round, stddev\n",
    "\n",
    "# Create Spark session (if not already running)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Convert pandas DataFrame  Spark DataFrame\n",
    "df_spotify = spark.createDataFrame(df_spotify_pd)\n",
    "\n",
    "# Register a temporary SQL view for SparkSQL (optional)\n",
    "df_spotify.createOrReplaceTempView(\"spotify_tracks\")\n",
    "\n",
    "# Show sample rows & schema\n",
    "df_spotify.show(5)\n",
    "df_spotify.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8efaac2-2482-407b-a97c-e7ff2447b8e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's see the average popularity by genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23a72f08-329a-4d9e-91fc-279fe9735669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"YXZnX3BvcHVsYXJpdHlfYnlfZ2VucmUgPSAoCiAgICBkZl9zcG90aWZ5Lmdyb3VwQnkoImdlbnJlIikKICAgIC5hZ2coCiAgICAgICAgcm91bmQoYXZnKCJwb3B1bGFyaXR5IiksIDIpLmFsaWFzKCJhdmdfcG9wdWxhcml0eSIpLAogICAgICAgIGNvdW50KCIqIikuYWxpYXMoIm51bV90cmFja3MiKQogICAgKQogICAgLmZpbHRlcihjb2woIm51bV90cmFja3MiKSA+IDUwKQogICAgLm9yZGVyQnkoY29sKCJhdmdfcG9wdWxhcml0eSIpLmRlc2MoKSkKKQoKZGlzcGxheShhdmdfcG9wdWxhcml0eV9ieV9nZW5yZSk=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView601523b\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView601523b\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView601523b\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView601523b) SELECT `avg_popularity`,SUM(`num_tracks`) `column_151d3fef953`,`genre` FROM q GROUP BY `avg_popularity`,`genre`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView601523b\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "genre",
             "id": "column_151d3fef954"
            },
            "x": {
             "column": "avg_popularity",
             "id": "column_151d3fef952"
            },
            "y": [
             {
              "column": "num_tracks",
              "id": "column_151d3fef953",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_151d3fef953": {
             "name": "num_tracks",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "60f56434-99e9-4f1f-8ecd-e09fff34d71f",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 71.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "avg_popularity",
           "type": "column"
          },
          {
           "column": "genre",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "avg_popularity",
           "type": "column"
          },
          {
           "alias": "column_151d3fef953",
           "args": [
            {
             "column": "num_tracks",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "column": "genre",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_popularity_by_genre = (\n",
    "    df_spotify.groupBy(\"genre\")\n",
    "    .agg(\n",
    "        round(avg(\"popularity\"), 2).alias(\"avg_popularity\"),\n",
    "        count(\"*\").alias(\"num_tracks\")\n",
    "    )\n",
    "    .filter(col(\"num_tracks\") > 50)\n",
    "    .orderBy(col(\"avg_popularity\").desc())\n",
    ")\n",
    "\n",
    "display(avg_popularity_by_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "146ef7b6-e833-41da-9b42-6168b60258e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Average Danceability by Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3146e698-2396-4593-bce3-c28bcea69b8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGFuY2VhYmlsaXR5X2J5X2dlbnJlID0gKAogICAgZGZfc3BvdGlmeS5ncm91cEJ5KCJnZW5yZSIpCiAgICAuYWdnKHJvdW5kKGF2ZygiZGFuY2VhYmlsaXR5IiksIDIpLmFsaWFzKCJhdmdfZGFuY2VhYmlsaXR5IikpCiAgICAub3JkZXJCeShjb2woImF2Z19kYW5jZWFiaWxpdHkiKS5kZXNjKCkpCikKCmRpc3BsYXkoZGFuY2VhYmlsaXR5X2J5X2dlbnJlKQo=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView9dadb51\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView9dadb51\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView9dadb51\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView9dadb51) SELECT `genre`,SUM(`avg_danceability`) `column_151d3fef957` FROM q GROUP BY `genre`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView9dadb51\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "genre",
             "id": "column_151d3fef956"
            },
            "y": [
             {
              "column": "avg_danceability",
              "id": "column_151d3fef957",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_151d3fef957": {
             "name": "avg_danceability",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "ce253173-e373-4e25-8439-c29897ef9820",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 72.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "genre",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "genre",
           "type": "column"
          },
          {
           "alias": "column_151d3fef957",
           "args": [
            {
             "column": "avg_danceability",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "danceability_by_genre = (\n",
    "    df_spotify.groupBy(\"genre\")\n",
    "    .agg(round(avg(\"danceability\"), 2).alias(\"avg_danceability\"))\n",
    "    .orderBy(col(\"avg_danceability\").desc())\n",
    ")\n",
    "\n",
    "display(danceability_by_genre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1774c0a-0ae7-408f-82ec-688ba5cace5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mood Classification (Energy + Valence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acbeb43f-abe6-4d15-aff7-c72b9ede44bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGZfc3BvdGlmeV9tb29kID0gZGZfc3BvdGlmeS53aXRoQ29sdW1uKAogICAgIm1vb2QiLAogICAgd2hlbigoY29sKCJlbmVyZ3kiKSA+IDAuNikgJiAoY29sKCJ2YWxlbmNlIikgPiAwLjYpLCAiSGFwcHkgLyBFbmVyZ2V0aWMiKQogICAgLndoZW4oKGNvbCgiZW5lcmd5IikgPCAwLjQpICYgKGNvbCgidmFsZW5jZSIpIDwgMC40KSwgIlNhZCAvIENhbG0iKQogICAgLndoZW4oKGNvbCgiZW5lcmd5IikgPiAwLjYpICYgKGNvbCgidmFsZW5jZSIpIDwgMC40KSwgIkFuZ3J5IC8gSW50ZW5zZSIpCiAgICAub3RoZXJ3aXNlKCJOZXV0cmFsIikKKQoKbW9vZF9zdW1tYXJ5ID0gKAogICAgZGZfc3BvdGlmeV9tb29kLmdyb3VwQnkoIm1vb2QiKQogICAgLmFnZygKICAgICAgICBjb3VudCgiKiIpLmFsaWFzKCJudW1fdHJhY2tzIiksCiAgICAgICAgcm91bmQoYXZnKCJwb3B1bGFyaXR5IiksIDIpLmFsaWFzKCJhdmdfcG9wdWxhcml0eSIpCiAgICApCiAgICAub3JkZXJCeShjb2woIm51bV90cmFja3MiKS5kZXNjKCkpCikKCmRpc3BsYXkobW9vZF9zdW1tYXJ5KQo=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewb1eb95e\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewb1eb95e\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewb1eb95e\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewb1eb95e) SELECT `mood`,SUM(`num_tracks`) `column_151d3fef976`,`avg_popularity` FROM q GROUP BY `avg_popularity`,`mood`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewb1eb95e\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "avg_popularity",
             "id": "column_151d3fef982"
            },
            "x": {
             "column": "mood",
             "id": "column_151d3fef981"
            },
            "y": [
             {
              "column": "num_tracks",
              "id": "column_151d3fef976",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "avg_popularity": {
             "type": "column",
             "yAxis": 0
            },
            "column_151d3fef973": {
             "name": "avg_popularity",
             "type": "column",
             "yAxis": 0
            },
            "column_151d3fef975": {
             "type": "column",
             "yAxis": 0
            },
            "column_151d3fef976": {
             "type": "column",
             "yAxis": 0
            },
            "num_tracks": {
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "a137323d-90b9-451b-abd0-a86edc7694fa",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 73.25,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "mood",
           "type": "column"
          },
          {
           "column": "avg_popularity",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "mood",
           "type": "column"
          },
          {
           "alias": "column_151d3fef976",
           "args": [
            {
             "column": "num_tracks",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "column": "avg_popularity",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_spotify_mood = df_spotify.withColumn(\n",
    "    \"mood\",\n",
    "    when((col(\"energy\") > 0.6) & (col(\"valence\") > 0.6), \"Happy / Energetic\")\n",
    "    .when((col(\"energy\") < 0.4) & (col(\"valence\") < 0.4), \"Sad / Calm\")\n",
    "    .when((col(\"energy\") > 0.6) & (col(\"valence\") < 0.4), \"Angry / Intense\")\n",
    "    .otherwise(\"Neutral\")\n",
    ")\n",
    "\n",
    "mood_summary = (\n",
    "    df_spotify_mood.groupBy(\"mood\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_tracks\"),\n",
    "        round(avg(\"popularity\"), 2).alias(\"avg_popularity\")\n",
    "    )\n",
    "    .orderBy(col(\"num_tracks\").desc())\n",
    ")\n",
    "\n",
    "display(mood_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4a65a09-be9f-49ff-aaee-a9e0dcb52838",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6181136400061919,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "LAB2 SparkSQL and Dataframes URBAN & SMADJA GR3",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
